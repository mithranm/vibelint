# Vibelint Analysis Reports

This directory contains organized analysis reports generated by vibelint workflows and commands.

## Directory Structure

- **`examples/`** - Example reports and configuration files for documentation
- **`justification/`** - File and method existence justification analysis
  - `current/` - Latest justification analysis results
  - `archived/` - Historical justification reports
- **`workflow/`** - General workflow execution reports
  - `current/` - Latest workflow results
  - `archived/` - Historical workflow reports
- **`analysis/`** - Code quality and architectural analysis
  - `current/` - Latest analysis results
  - `archived/` - Historical analysis reports

## File Naming Convention

Reports are automatically timestamped using the format: `YYYY-MM-DD-HHMMSS-<type>.json`

## Configuration

The default output directories can be configured in `pyproject.toml`:

```toml
[tool.vibelint.reports]
output_dir = ".vibelint-reports"
justification_dir = ".vibelint-reports/justification/current"
workflow_dir = ".vibelint-reports/workflow/current"
analysis_dir = ".vibelint-reports/analysis/current"
auto_archive_days = 7
```

## Example Report

See `example-analysis.json` for a sample of what vibelint detects:

- **Code Smells**: Long methods, magic numbers, uncommunicative names
- **Architecture Issues**: SRP violations, coupling problems
- **Silent Failures**: Exception handlers that swallow errors
- **Dead Code**: Unused functions, unreferenced definitions
- **Type Issues**: Missing annotations, poor typing practices
- **Namespace Collisions**: Variable name conflicts across modules

## Usage

Generate your own reports:

```bash
# Quick check on modified files
PYTHONPATH=src vibelint check path/to/files.py

# Comprehensive analysis with JSON output
PYTHONPATH=src vibelint check src/ --format json > .vibelint-reports/$(date +%Y-%m-%d-%H%M%S)-analysis.json

# Filter results by rule type
grep -A5 -B1 '"rule": "ARCHITECTURE-LLM"' .vibelint-reports/latest.json

# Get rule frequency breakdown
grep '"rule":' .vibelint-reports/latest.json | sort | uniq -c | sort -nr
```

## LLM Workflow Tracing

See `example-llm-trace.json` for complete end-to-end logging of LLM analysis workflows:

- **Complete LLM Call Traces**: Every prompt, response, token usage, and latency
- **Routing Decisions**: Why each LLM was selected (fast vs orchestrator)
- **Workflow Timeline**: Start/end times, duration, and event sequences
- **Error Tracking**: Failures and exceptions in the analysis pipeline
- **Cost Analysis**: Token usage and estimated costs across all LLM calls

This comprehensive tracing enables:
- **Debugging**: Trace exactly what went wrong in failed analyses
- **Auditing**: Full accountability of AI decision-making process
- **Optimization**: Identify bottlenecks and improve routing efficiency
- **Cost Control**: Monitor and optimize LLM usage costs

## Single LLM Configuration

See `example-single-llm-config.toml` for configuring vibelint with just one LLM:

- **Fast LLM only**: Basic AI features (code smells, docstrings, simple validation)
- **Orchestrator LLM only**: All AI features but less efficient routing
- **Modular design**: Unconfigured features gracefully degrade
- **Fail-fast behavior**: Configured but unavailable models abort immediately

This allows users with limited resources to still benefit from vibelint's AI capabilities.

All reports except examples are gitignored to keep the repository clean.